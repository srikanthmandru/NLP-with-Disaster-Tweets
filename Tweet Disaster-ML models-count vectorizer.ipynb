{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV , cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from collections import  Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\n",
    "from keras.initializers import Constant\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "stop_words =set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(31415)\n",
    "np.random.seed(31415)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train = pd.read_csv('data/train.csv')\n",
    "tweets_test = pd.read_csv('data/test.csv')\n",
    "tweets_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7613 rows and 5 columns in train\n",
      "There are 3263 rows and 4 columns in train\n"
     ]
    }
   ],
   "source": [
    "print('There are {} rows and {} columns in train'.format(tweets_train.shape[0],tweets_train.shape[1]))\n",
    "print('There are {} rows and {} columns in train'.format(tweets_test.shape[0],tweets_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'samples')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=tweets_train.target.value_counts()\n",
    "sns.barplot(x.index,x)\n",
    "plt.gca().set_ylabel('samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Text Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([tweets_train,tweets_test] , sort = False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3258</td>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3259</td>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3261</td>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3262</td>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10876 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...     1.0  \n",
       "1                Forest fire near La Ronge Sask. Canada     1.0  \n",
       "2     All residents asked to 'shelter in place' are ...     1.0  \n",
       "3     13,000 people receive #wildfires evacuation or...     1.0  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...     1.0  \n",
       "...                                                 ...     ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...     NaN  \n",
       "3259  Storm in RI worse than last hurricane. My city...     NaN  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...     NaN  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...     NaN  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...     NaN  \n",
       "\n",
       "[10876 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess text\n",
    "\n",
    "Based on the Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    # remove numbers\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    \n",
    "    ## Remove URLs\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text1 = url.sub(r'',text)\n",
    "    \n",
    "    ## Remove HTML tags \n",
    "    html = re.compile(r'<.*?>')\n",
    "    text2 = html.sub(r'',text1)\n",
    "    \n",
    "    ## Remove Emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text2 = emoji_pattern.sub(r'', text2)\n",
    "\n",
    "    ## Remove punctuation\n",
    "    \n",
    "    table= str.maketrans('','',string.punctuation)\n",
    "    text3 = text2.translate(table)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return text3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RockyFire Update  California Hwy  closed in bo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood disaster Heavy rain causes flash floodin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Im on top of the hill and I can see a fire in ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Theres an emergency evacuation happening now i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Im afraid that the tornado is coming to our area</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1   4     NaN      NaN              Forest fire near La Ronge Sask Canada   \n",
       "2   5     NaN      NaN  All residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN   people receive wildfires evacuation orders in...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby Alaska as s...   \n",
       "5   8     NaN      NaN  RockyFire Update  California Hwy  closed in bo...   \n",
       "6  10     NaN      NaN  flood disaster Heavy rain causes flash floodin...   \n",
       "7  13     NaN      NaN  Im on top of the hill and I can see a fire in ...   \n",
       "8  14     NaN      NaN  Theres an emergency evacuation happening now i...   \n",
       "9  15     NaN      NaN   Im afraid that the tornado is coming to our area   \n",
       "\n",
       "   target  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  \n",
       "5     1.0  \n",
       "6     1.0  \n",
       "7     1.0  \n",
       "8     1.0  \n",
       "9     1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text = df.text.apply(preprocess_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_preprocess_text(text):\n",
    "    \n",
    "    text = WhitespaceTokenizer().Tokenize(text)\n",
    "    \n",
    "    \n",
    "    # lemmatize\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    text = ' '.join((lmtzr.lemmatize(i)) for i in text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RockyFire Update  California Hwy  closed in bo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood disaster Heavy rain causes flash floodin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Im on top of the hill and I can see a fire in ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Theres an emergency evacuation happening now i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Im afraid that the tornado is coming to our area</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1   4     NaN      NaN              Forest fire near La Ronge Sask Canada   \n",
       "2   5     NaN      NaN  All residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN   people receive wildfires evacuation orders in...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby Alaska as s...   \n",
       "5   8     NaN      NaN  RockyFire Update  California Hwy  closed in bo...   \n",
       "6  10     NaN      NaN  flood disaster Heavy rain causes flash floodin...   \n",
       "7  13     NaN      NaN  Im on top of the hill and I can see a fire in ...   \n",
       "8  14     NaN      NaN  Theres an emergency evacuation happening now i...   \n",
       "9  15     NaN      NaN   Im afraid that the tornado is coming to our area   \n",
       "\n",
       "   target  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  \n",
       "5     1.0  \n",
       "6     1.0  \n",
       "7     1.0  \n",
       "8     1.0  \n",
       "9     1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text = df.text.apply(preprocess_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.text[:7613]\n",
    "test_data = df.text[7613:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this earthquake Ma...\n",
       "1                   Forest fire near La Ronge Sask Canada\n",
       "2       All residents asked to shelter in place are be...\n",
       "3        people receive wildfires evacuation orders in...\n",
       "4       Just got sent this photo from Ruby Alaska as s...\n",
       "                              ...                        \n",
       "7608    Two giant cranes holding a bridge collapse int...\n",
       "7609    ariaahrary TheTawniest The out of control wild...\n",
       "7610                        M  UTCkm S of Volcano Hawaii \n",
       "7611    Police investigating after an ebike collided w...\n",
       "7612    The Latest More Homes Razed by Northern Califo...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer = 'word', ngram_range=(1, 2) ,stop_words = stop_words, max_df = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_data)\n",
    "\n",
    "## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n",
    "# that the tokens in the train vectors are the only ones mapped to the test vectors - \n",
    "# i.e. that the train and test vectors use the same set of tokens.\n",
    "test_vectors = count_vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dense = train_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7613x63568 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 128826 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3263x63568 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 33201 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors_dense = test_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'max_iter': 10}\n",
      "Best score is 0.611629213807759\n"
     ]
    }
   ],
   "source": [
    "# Setup the hyperparameter grid\n",
    "\n",
    "# c_space = np.logspace(-8, 2, 10)\n",
    "param_grid = {'max_iter' : [10, 5] }\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = linear_model.LogisticRegression( penalty = 'none', solver ='lbfgs', class_weight = 'balanced' )\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5 , scoring = 'f1')\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(train_vectors, tweets_train['target'])\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_param_grid = {'alpha' : np.logspace(-2,1,20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf = linear_model.RidgeClassifier()\n",
    "# ridge_clf  = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'alpha': 4.832930238571752}\n",
      "Best score is 0.557221185404533\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ridgeclf_cv = GridSearchCV(estimator = ridge_clf, param_grid = ridge_param_grid , cv=5 , scoring = 'f1' , n_jobs = -1)\n",
    "\n",
    "\n",
    "ridgeclf_cv.fit(train_vectors, tweets_train['target'])\n",
    "\n",
    "\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(ridgeclf_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(ridgeclf_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58341463, 0.46725664, 0.53547297, 0.47152847, 0.66226259])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(ridge_clf, train_vectors , tweets_train['target'] , cv=5 , scoring = 'f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                max_iter=None, normalize=False, random_state=None,\n",
       "                solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.fit(train_vectors, tweets_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf_test_preds = ridge_clf.predict(test_vectors)\n",
    "ridge_clf_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'l1_ratio': 0.1, 'max_iter': 100}\n",
      "Best score is 0.5933973224744554\n"
     ]
    }
   ],
   "source": [
    "# Setup the hyperparameter grid\n",
    "\n",
    "# c_space = np.logspace(-8, 2, 10)\n",
    "# l1_ratio = np.logspace(-1, 0, 4)\n",
    "elasticnet_param_grid = {'max_iter' : [100], 'l1_ratio' : [0.2, 0.1, 0.5] }\n",
    "\n",
    "# Instantiate a logistic regression classifier: elasticnet_clf\n",
    "elasticnet_clf = linear_model.LogisticRegression( penalty = 'elasticnet', solver ='saga', class_weight = 'balanced')\n",
    "\n",
    "# Instantiate the GridSearchCV object: elasticnet_clf_cv\n",
    "elasticnet_clf_cv = GridSearchCV(elasticnet_clf, elasticnet_param_grid, cv=2 , scoring = 'f1')\n",
    "\n",
    "# Fit it to the data\n",
    "elasticnet_clf_cv.fit(train_vectors, tweets_train['target'])\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(elasticnet_clf_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(elasticnet_clf_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dec_tree_param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 2000),\n",
    "              \"min_samples_leaf\": randint(1, 20),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "dec_tree_cv = RandomizedSearchCV(estimator = dec_tree, \n",
    "                                 param_distributions = dec_tree_param_dist, \n",
    "                                 cv=5, scoring = 'f1')\n",
    "\n",
    "\n",
    "dec_tree_cv.fit(train_vectors, tweets_train['target'])\n",
    "\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(dec_tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(dec_tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Bagging Classifier , Random Forests\n",
    "### Boosting - Adaboost, Gradient Boosting\n",
    "\n",
    "### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging - Random Forests classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_rf_clf'\n",
    "params_rf_clf = {\n",
    "    'n_estimators' : [6, 8, 10, 12] , 'criterion' : ['entropy'],\n",
    "    'max_features' : ['auto', 'sqrt'], 'class_weight' : ['balanced'] ,\n",
    "    'min_samples_leaf' : [2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate grid_rf_clf\n",
    "grid_rf_clf = GridSearchCV(estimator = rf_clf,\n",
    "                       param_grid = params_rf_clf,\n",
    "                       scoring= 'f1',\n",
    "                       cv = 5,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit it to the data\n",
    "grid_rf_clf.fit(train_vectors, tweets_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned Random Forests Parameters: {}\".format(grid_rf_clf.best_params_))\n",
    "print(\"Best score is {}\".format(grid_rf_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned Random Forests Parameters: {}\".format(grid_rf_clf.best_params_))\n",
    "print(\"Best score is {}\".format(grid_rf_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_clf = grid_rf_clf.best_estimator_\n",
    "best_rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_clf.fit(train_vectors, tweets_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data = best_rf_clf.feature_importances_,\n",
    "                        index = count_vectorizer.get_feature_names() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()[-50:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 20))\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting - Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_adaboost_clf'\n",
    "params_adaboost_clf = {\n",
    "    'n_estimators' : [1, 2 ]  , 'base_estimator' : [ logreg ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate adaboost_clf\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "\n",
    "# Instantiate grid_rf_clf\n",
    "grid_adaboost_clf = GridSearchCV(estimator = adaboost_clf,\n",
    "                       param_grid = params_adaboost_clf,\n",
    "                       scoring= 'f1',\n",
    "                       cv = 3,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_adaboost_clf.fit(train_vectors, tweets_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned Adaboost Parameters: {}\".format(grid_adaboost_clf.best_params_))\n",
    "print(\"Best score is {}\".format(grid_adaboost_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_adaboost_clf = grid_adaboost_clf.best_estimator_\n",
    "best_adaboost_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1 ,10, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {'C' : np.logspace(0, 1, 12) , 'gamma': ['auto', 'scale']  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "svmclf_cv = GridSearchCV(estimator = svm_clf, param_grid = svm_param_grid , cv=5 , scoring = 'f1' , n_jobs = -1)\n",
    "\n",
    "# Fit it to the data\n",
    "svmclf_cv.fit(train_vectors, tweets_train['target'])\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(svmclf_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(svmclf_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine best models through VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VotingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('Logistic Regression', logreg), ('random forest', best_rf_clf) , \n",
    "               ( 'Adaboost classifier' , best_adaboost_clf )]\n",
    "\n",
    "# Instantiate a VotingClassifier voting_clfs\n",
    "voting_clfs = VotingClassifier(estimators=classifiers , voting = 'soft' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clfs_scores = cross_val_score(voting_clfs, train_vectors , tweets_train['target'] , cv=5 , scoring = 'f1')\n",
    "voting_clfs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clfs_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = clf.predict(test_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
